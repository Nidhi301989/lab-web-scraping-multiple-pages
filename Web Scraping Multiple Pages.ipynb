{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97ec373",
   "metadata": {},
   "source": [
    "# Lab | Web Scraping Multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaf7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url_rolling_stone = \"https://www.rollingstone.com/charts/songs/\"\n",
    "response_rs = requests.get(url_rolling_stone)\n",
    "soup_rs = BeautifulSoup(response_rs.content, 'html.parser')\n",
    "\n",
    "songs_rs = [song.get_text().strip() for song in soup_rs.find_all('h3', class_='c-chart__title')]\n",
    "artists_rs = [artist.get_text().strip() for artist in soup_rs.find_all('span', class_='c-chart__subtitle')]\n",
    "\n",
    "df_rs = pd.DataFrame({'Song': songs_rs, 'Artist': artists_rs})\n",
    "df_rs.to_csv('rolling_stone_top_100.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64feb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://en.wikipedia.org/wiki/Lists_of_songs', 'https://en.wikipedia.org/wiki/Talk:Lists_of_songs', 'https://en.wikipedia.org/wiki/Lists_of_songs', 'https://en.wikipedia.org/w/index.php?title=Lists_of_songs&action=edit', 'https://en.wikipedia.org/w/index.php?title=Lists_of_songs&action=history', 'https://en.wikipedia.org/wiki/Lists_of_songs', 'https://en.wikipedia.org/w/index.php?title=Lists_of_songs&action=edit', 'https://en.wikipedia.org/w/index.php?title=Lists_of_songs&action=history', 'https://en.wikipedia.org/wiki/Special:WhatLinksHere/Lists_of_songs', 'https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Lists_of_songs']\n"
     ]
    }
   ],
   "source": [
    "# URL of the Wikipedia page listing songs\n",
    "url_wikipedia = \"https://en.wikipedia.org/wiki/Lists_of_songs\"\n",
    "response_wp = requests.get(url_wikipedia)\n",
    "soup_wp = BeautifulSoup(response_wp.content, 'html.parser')\n",
    "\n",
    "song_links = [link.get('href') for link in soup_wp.find_all('a') if 'Lists_of' in str(link.get('href'))]\n",
    "\n",
    "song_links = [f\"https://en.wikipedia.org{link}\" for link in song_links if link]\n",
    "\n",
    "print(song_links[:10])  # Print the first 10 links as a sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b7ec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#bodyContent', '/wiki/Main_Page', '/wiki/Wikipedia:Contents', '/wiki/Portal:Current_events', '/wiki/Special:Random', '/wiki/Wikipedia:About', '//en.wikipedia.org/wiki/Wikipedia:Contact_us', '/wiki/Help:Contents', '/wiki/Help:Introduction', '/wiki/Wikipedia:Community_portal']\n"
     ]
    }
   ],
   "source": [
    "url_python = 'https://en.wikipedia.org/wiki/Python'\n",
    "response_python = requests.get(url_python)\n",
    "soup_python = BeautifulSoup(response_python.content, 'html.parser')\n",
    "\n",
    "python_links = [a.get('href') for a in soup_python.find_all('a', href=True)]\n",
    "print(python_links[:10])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9501df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Home', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'User Guide', 'USLM Schema and stylesheet', 'stylesheet', 'GPO', 'Currency', 'Prior Release Points', 'Annual Historical Archives', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '[XML]', '[XHTML]', '[PCC]', '[PDF]', '٭', '[XML]', '[XHTML]', '[PCC]', '[PDF]', 'About the Office', 'Privacy Policy']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the US Code Download Page\n",
    "url_uscode = 'http://uscode.house.gov/download/download.shtml'\n",
    "response_uscode = requests.get(url_uscode)\n",
    "soup_uscode = BeautifulSoup(response_uscode.content, 'html.parser')\n",
    "\n",
    "titles_changed = [title.get_text(strip=True) for title in soup_uscode.find_all('a')]\n",
    "\n",
    "print(titles_changed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8decde96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
      "     ---------------------------------------- 9.7/9.7 MB 17.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "     ------------------------------------- 481.7/481.7 kB 31.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Collecting websocket-client~=1.8\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting attrs>=23.2.0\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 63.0/63.0 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Installing collected packages: websocket-client, sniffio, h11, exceptiongroup, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 0.58.0\n",
      "    Uninstalling websocket-client-0.58.0:\n",
      "      Successfully uninstalled websocket-client-0.58.0\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.4.0\n",
      "    Uninstalling attrs-21.4.0:\n",
      "      Successfully uninstalled attrs-21.4.0\n",
      "Successfully installed attrs-24.2.0 exceptiongroup-1.2.2 h11-0.14.0 outcome-1.3.0.post0 selenium-4.25.0 sniffio-1.3.1 trio-0.27.0 trio-websocket-0.11.1 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41738f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ysql-connector-python (c:\\users\\ashis\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e52daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALEXIS FLORES', 'BHADRESHKUMAR CHETANBHAI PATEL', 'ALEJANDRO ROSALES CASTILLO', 'DONALD EUGENE FIELDS II', \"VITEL'HOMME INNOCENT\", 'WILVER VILLEGAS-PALOMINO', 'RUJA IGNATOVA', 'ARNOLDO JIMENEZ', 'OMAR ALEXANDER CARDENAS', 'YULAN ADONAY ARCHAGA CARIAS']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Setup the ChromeDriver using the Service class\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get('https://www.fbi.gov/wanted/topten')\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "soup_fbi = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "fbi_wanted = [name.get_text().strip() for name in soup_fbi.find_all('h3', class_='title')]\n",
    "print(fbi_wanted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "030ad766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Magnitude': 'Min:', 'Location': '', 'Date': ''}\n",
      "{'Magnitude': 'Max:', 'Location': '', 'Date': ''}\n",
      "{'Magnitude': 'Region Name', 'Location': '[x]Send checked', 'Date': ''}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Setup the ChromeDriver using the Service class\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "url_earthquakes = 'https://www.emsc-csem.org/Earthquake/'\n",
    "driver.get(url_earthquakes)\n",
    "\n",
    "time.sleep(5) \n",
    "\n",
    "soup_earthquakes = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "earthquakes = []\n",
    "table = soup_earthquakes.find('table')  \n",
    "if table:\n",
    "    for row in table.find_all('tr')[1:]: \n",
    "        if len(cols) >= 3: \n",
    "            magnitude = cols[0].get_text(strip=True)\n",
    "            location = cols[1].get_text(strip=True)\n",
    "            date = cols[2].get_text(strip=True)\n",
    "            earthquakes.append({\n",
    "                'Magnitude': magnitude,\n",
    "                'Location': location,\n",
    "                'Date': date\n",
    "            })\n",
    "\n",
    "for quake in earthquakes[:20]:\n",
    "    print(quake)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdad3f",
   "metadata": {},
   "source": [
    "# 1st Prototype and our project following the flowchart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e330bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "def scrape_hot_songs():\n",
    "    url = \"https://www.billboard.com/charts/hot-100/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    hot_songs = []\n",
    "    for song in soup.find_all('h3', class_='c-title'):\n",
    "        title = song.get_text(strip=True)\n",
    "        hot_songs.append(title)\n",
    "\n",
    "    return hot_songs\n",
    "\n",
    "def recommend_song(input_song, hot_songs):\n",
    "        recommendations = [song for song in hot_songs if song != input_song]\n",
    "        return random.choice(recommendations) if recommendations else None\n",
    "    else:\n",
    "        return \"Recommend from other songs list.\"\n",
    "\n",
    "hot_songs = scrape_hot_songs()\n",
    "user_input = input(\"Enter a song title: \") \n",
    "recommended_song = recommend_song(user_input, hot_songs)\n",
    "\n",
    "print(f\"Recommended Song: {recommended_song}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52578bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
